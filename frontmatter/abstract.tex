%!TEX root = ../dissertation.tex
% the abstract

%should state the problem, describe the methods and procedures used, and give the main results or conclusions of the research.

How do humans reason intelligently in a complex and ever-changing world within limits on energy, data and time? How might an understanding of this help us build human-like artificial intelligence? Structured Bayesian models provide a normative account of rational behavior. Such models have made great progress towards understanding and describing the flexibility of human behavior, as well as the efficiency of their learning, in the presence of uncertainty and across a variety of domains. However, within limits on computational resources normative Bayesian inferences are often intractable. In the kinds of high-dimensional spaces in which humans regularly function very adaptively, exact Bayesian inference would require tremendous computational resources that seem outside the realm of possibility given our brain's limited time and energy.
% Yet many human behaviors are very well replicated by exact Bayesian inference in complex, structured and high-dimensional models.
%Yet many behaviors in very high dimensional and structured domains have been characterized as close to Bayesian. How might humans perform these complex inferences efficiently? This leads to the second key criticism of normative inference. 
Further, extensive research in cognitive psychology and behavioral economics has demonstrated that human behavior is in fact `irrational', and often deviates significantly from normative Bayesian inference even in putatively simple problems, demonstrating a wide range of cognitive biases. How can we reconcile these shortcomings of structured probabilistic models of human cognition, with the many advantages they confer? %Chapters \ref{chap:intro} and \ref{chap:psych} set the context for this thesis and discuss these problems and past solutions to them at greater length. 

The goal of this thesis is to provide such a reconciliation, and thereby build a more complete picture of human-like intelligence. The key insight I build on is that humans are not general purpose computing machines, and neither should artificial systems that hope to emulate human intelligence. We are instead `ecologically rational', adapting to structure in our environments to make the best use of our limited access to data, time, and energy. 


%The goal of this thesis is move towards this more complete picture by taking a renewed consideration of the role of the environment in which intelligent systems learn and behave. 

The first contribution of this thesis (in Chapters \ref{chap:approx} \& \ref{chap:amort}) is to propose algorithms for approximating exact Bayesian inference within structured models that reduce the computational costs of inference by leveraging underlying environmental structure. This adaptation to the environment is achieved by a process of amortization -- i.e. of seeing patterns in the sets of queries faced, and intelligently re-using computations performed in the service of previous queries. This makes inferences in structured Bayesian models, that were previously computationally intractable, more plausible.

%An inference procedure that leverages environmental structure serves well for queries that are frequent, but can strongly bias inference in case of infrequent queries. 
Amortization can be very useful when previous experience is similar to the query at hand. However, it can also lead to errors when the current query is not representative of past experience but this past experience is still erroneously re-used. Ecologically rational strategies learned from previous experience therefore will work for the vast majority of frequent queries, but can lead to biases for infrequent queries. The second key contribution of this thesis (in Chapters \ref{chap:MCMC}--\ref{chap:LTI}) is to demonstrate that the patterns of errors this mechanism gives rise to can exactly replicate several human cognitive biases. New predictions from these proposed models are also tested in several novel behavioral experiments.

Several machine-learning methods also implicitly amortize computations. I demonstrate that ecological rationality induced by this amortization can also explain behavioral patterns in modern machine learning. Further, in the case of machine intelligence, we have full control over the environments these systems access. A third contribution of this thesis (in Chapters \ref{chap:sentences} \& \ref{chap:causal}) is to show how a better understanding of the role of the environment in the inference procedures learned by ecologically rational systems can allow us to artificially engineer new kinds of intelligent behaviors, including inference procedures that permit causal reasoning and compositional language understanding, by engineering the learning environments of machine-learning systems. These experiments in machine intelligence also provide insights into how these central tenets of intelligence might arise in humans.

%These contributions reconcile the crucial shortcomings of a leading approach to human-like intelligence, by putting back in the spotlight the central role of the environment in shaping intelligent behavior. 

Ecological rationality has so far largely been a philosophical idea, and has at most been used in descriptive theories of intelligent behavior. By taking an algorithmic approach to ecological rationality -- i.e. making explicit claims of how it can be implemented at the level of plausible psychological mechanisms -- I develop new models for human probabilistic inference that can elegantly explain both its remarkable successes and surprising failures. This direction of research also opens up a new approach to engineering artificial forms of intelligence, via manipulation of their learning environments, providing new avenues towards understanding and building machines with human-like intelligence.
