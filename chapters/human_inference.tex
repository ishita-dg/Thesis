%!TEX root = ../dissertation.tex
%\begin{savequote}[75mm]
%Nulla facilisi. In vel sem. Morbi id urna in diam dignissim feugiat. Proin molestie tortor eu velit. Aliquam erat volutpat. Nullam ultrices, diam tempus vulputate egestas, eros pede varius leo.
%\qauthor{Quoteauthor Lastname}
%\end{savequote}


\chapter{Probabilistic inference in humans}
\label{chap:psych}

In this section, I will first provide some background in Bayesian models of cognition, what they provide and where they fall short. I will then provide an overview of approaches that have attempted to address these shortcomings: in particular, I will summarize two major lines of work -- the biases and heuristics literature, and the literature on resource-rationality -- as well as the questions they still leave open. I will then build a case for how algorithmic approaches to ecological rationality can unify and extend these approaches.

\section{Bayesian models of cognition}
Bayesian models of cognition follow in the tradition of `rational analysis'\cite{shepard1987toward, anderson1990adaptive}: an approach to cognitive science that frames cognition as an approximately optimal response to the structure and uncertainty present in natural tasks and environments. This framework specifies the goals of a system and the information it has access to, and makes predictions about behavior by determining what would be optimal under these assumptions. A central contribution to such models is that they go beyond describing phenomena and mechanisms, and attempt to provide insight into why the processes might be as they are. Since the optimal response can be derived from the assumptions, these models make testable predictions about behavior under new assumptions that can be empirically manipulated, and thereby facilitate the scientific process of building, falsifying and improving theories.

Bayesian models posit that humans reason probabilistically, following the tenets of Bayes' rule. Probability theory specifies how rational agents should reason in situations of uncertainty\cite{hacking2006emergence, gigerenzer1990empire}, and is therefore an important part of rational models of cognition. The motivation for using an explicitly Bayesian approach to probabilistic inference is that they provide an answer -- at least in principle -- of how humans go beyond the data collected solely from their own experience of the world, integrate it with abstract prior information, and form intelligent \textit{inductive inference}. Many problems in our everyday life are vastly under-specified by our sensory input. To take an example from \citet{griffiths2008bayesian}: deducing with certainty the color of an object simply by observing light reflected from it is impossible since the input we receive is a combination of the light illuminating the scene, and the spectrum reflected by the object. Bayesian models posit that the reason we are nonetheless able to make reasonable guesses about the colors of objects around us is that we have strong expectations about the spectrum of light that usually illuminates our surroundings. This takes the form of a priori knowledge gained from previous experience, that we can integrate with the visual signal received -- using Bayes' rule -- to make decent guesses about the problem at hand.

While such models have been used to successfully and parsimoniously model behavior in several domains, two key concerns remain. First, exactly applying Bayes' rule is often intractable. This is an established and extensively studied problem in statistics. We discuss the details of this problem and potential solutions to it in Chapter \ref{chap:approx}. Second, significant empirical evidence suggests that humans responses often deviate significantly from Bayes optimal in systematic and predictable ways\citep{tversky1974judgment, slovic1971comparison, grether1980bayes, fischhoff1983hypothesis}. Both of these raise concerns with whether or not humans are actually performing exact Bayesian inference, and has led to much controversy\citep{mellers2001frequency, gigerenzer1996narrow, samuels2012ending}. 

In the next section we discuss some other approaches to modeling human inference that skirt these concerns with exact Bayesian models of cognition. These approaches move away from the rational analysis perspective and move closer to the psychological mechanisms underlying behavior -- but do so in very different ways.

\section{Bounded rationality}

We establish a stronger connection between rational models of cognition and psychological mechanisms by recognizing that humans are resource limited, and computing optimal responses might be outside the scope of the psychological mechanisms available at their disposal. This idea was formalized in \citet{simon1955behavioral} as `bounded rationality': the idea that the rationality -- and therefore the optimality -- of individual actors is limited by the information they have, the limitations on their cognitive resources, as well the finite amount of time they have to make decisions. Several different strategies for taking into account the effects of information-processing constraints have been considered. Here we consider two key ones; first, we consider rejecting the principle of rational analysis in favor of finding simple but effective heuristics; and second, we consider incorporating constraints into the optimization process.

\subsection{Heuristics and Biases: shortcuts around optimal inference}

If the goal is achieving bounded rationality, there is no reason to retain rational analysis. We can posit other heuristic mechanisms by which people arrive at responses, that might be far easier to compute. Several of these might provide reasonably good responses most of the time -- satisfying the claim of being `boundedly' rational -- yet have no real connection to optimal inference. 

Therefore, the argument is that while certain behaviors might look `as if' people are engaging in optimal Bayesian inference, they might be doing something completely different -- viz a heuristic strategy that is much easier to implement. In cases where this heuristic contradicts optimal Bayesian inference, we get the systemic and predictable deviations from optimality as recorded in empirical studies. This approach has been hugely influential in behavioral economics, -- pioneered by Kahneman and Tversky\cite{tversky} -- as well as in psychology (see \citet{gigerenzer2002bounded} for a review). 

A crucial shortcoming of these approaches however is that while they answer the `what' of the processes underlying human inference, by relinquishing the optimization perspective of rational analysis, they often fail to account for the `why'\footnote{\citet{gigerenzer2008heuristics} does address a version of the `why' question by characterizing heuristic judgment as a rational response to structure in the environment. i.e. by claiming that heuristics are `ecologically rational'. We discuss this in greater detail in the next section, as well as point out the shortcomings of this explanation.} This can lead to lists of heuristics, conceived with inspiration from the specific modes of failure noted in human inference, without a unifying theory of how these heuristics are learned or where they come from. 

Another problem is that of\emph{strategy selection} \citep{gigerenzer2008heuristics, marewski2014strategy} -- how do we choose a heuristic for a specific context? Most models of strategy selection assume that people are able to assess the usefulness of a strategy, through cost-benefit analysis \citep{johnson85, beach1978contingency, lieder2017strategy}, reinforcement learning \citep{erev05, rieskamp06}, or based on the strategy's applicability in a particular domain \citep{marewski2011cognitive, schulz2016simple} -- which in an of itself might be a resource-intensive process outside the scope of the posited limitations on cognitive resources. Further, all of these approaches require, either explicitly or implicitly, a feedback signal. This requirement poses a problem in inferential settings where no feedback is available. People can readily answer questions like ``How likely is it that a newly invented machine could transform a rose into a blackbird?'' \citep{Griffiths15} which lack an objective answer even in principle. 


Finally, while these heuristics have been studied primarily in the domain of judgment and decision making, probabilistic inference in humans is important for a much wider set of domains in humans -- including concept learning, causal attributions, and language learning. Many of these heuristics might not transfer well to these other domains, in addition, they might be very hard to isolate and study in these domains. I broader, more general theory of how heuristic inference arises in humans, as driven by some underlying principles, would allow a common theory of probabilistic inference humans -- Bayesian or otherwise -- that spans domains.
%
% \cite{gigerenzer2008heuristics} furthers the idea that heuristics are adaptive to the environment, furthering the notion of ecological rationality. However, this still remains an `as-if' model of  Without a theory for the r here is how these heuristics are learned, and how they are selected among.

\subsection{Computational rationality: optimization under constraints}

Another approach is to explicitly account for the costs of computation in the overall optimization. These usually entail specifying the costs of information-gathering, cognitive resources, and time, as well as specifying an algorithm for computing a response that makes specific demands on the amounts of these resources it needs. By including these resource limitations in the optimization problem, we arrive at a bounded rational solution.

There are two key approaches to this problem. The first is closer to a computational level account that describes behavior as resource-rational \citep{Vul2014,griffiths2015, schulz2016simple} and posits a new optimization problem that also account for the costs of internal computations. This problem however, punts the problem one step ahead -- the bounded optimal solution that accounts for resources in addition to the original optimization objective might be even harder to optimize than the original optimization.

One way around that is to building rational process models where the cost function can be locally estimated. In such a framework, increased investment of computational resources provides lower marginal returns on how close we get to the optimal response\cite{gershman15}. Once the additional utility of increased investment is low, we can stop the computation. in Chapter \ref{chap:MCMC} we introduce one such model. However, several models for resource-rational inference do not fall into this smooth optimization regime. While much progress has been made in characterizing several behaviors as resource-rational, they continue -- without further assumptions -- to fall into the trap of turtles all the way down.

Further, most rational process models are based on domain-general algorithms, and thus struggle to explain the context-sensitivity of inferential errors (see \citet{mercier2017enigma} for a similar argument). Some models explain why certain kinds of queries induce certain kinds of errors \citep{dasgupta2017hypotheses}, but do not explain how errors can be modulated by other queries in the same context \citep{gershman2014amortized,dasgupta2018remembrance}. 

%involved in rational analysis (e.g.,
%Anderson, 1990), handicapping rational models to produce behavior closer to that of human participants (e.g.,
%Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003),


\section{Ecological rationality}

In this thesis, I propose a way to combine these two into one, using the powerful idea of re-use. In Chapter \ref{chap:amort} I discuss a more general principle of amortization and how it provides an algorithmic approach to ecological rationality. But before we move on to amortization, let us fisrt better understand the computational problem we need to solve and the various approaches to it -- and be in a better position to understand where amortization fits in.

%\subsection{Algorithmic approaches to ecological rationality}

