\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces \textbf {Subadditivity}. MCMC estimates were made for the following queries: Given the symptoms \emph {fever, nausea} and \emph {fatigue}, (a) Packed: what is the probability that these symptoms were caused by the presence of a gastrointestinal disease? (b) Unpacked to typical examples: what is the probability that these were caused by the presence of food poisoning, stomach flu, or any other gastrointestinal diseases? The estimate for the unpacked condition is higher than that of the packed condition. The difference between these estimates is represented by the red line. This effect diminishes as the number of samples increases.\relax }}{30}{figure.caption.5}
\contentsline {figure}{\numberline {2.2}{\ignorespaces \textbf {Superadditivity}. MCMC-estimates were made for the following queries: Given the symptoms \emph {fever, nausea} and \emph {fatigue}, (a) Packed: What is the probability that these symptoms were caused by the presence of gastrointestinal disease? (b) Unpacked to atypical examples: What is the probability is that these symptoms were caused by the presence of gastroenteritis, stomach cancer, or any other gastrointestinal disease? The estimate for the unpacked condition is lower than that of the packed condition. The difference between these estimates is represnted by the red line. This effect diminishes as the number of samples increases.\relax }}{32}{figure.caption.6}
\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf {Weak evidence effect}. MCMC estimates were made for the following queries: Given the symptoms \emph {fever, nausea} and \emph {fatigue}, (a) Control: What is the probability that these symptoms were caused by the presence of gastrointestinal disease? (b) Evidence for a weak cause: What is the probability that these symptoms were caused by the presence of gastrointestinal disease, assuming the patient's grandmother was diagnosed with stomach cancer? The increase in support of the weak cause (stomach cancer) is modeled by increasing the prior probability of stomach cancer from 0.05 to 0.06. The estimate from the weak evidence chain is lower than that from the control chain. The difference between these estimates is represented by the red line. The effect diminishes as the number of samples increases.\relax }}{34}{figure.caption.7}
\contentsline {figure}{\numberline {2.4}{\ignorespaces \textbf {Dud alternative effect}. MCMC estimates were made for the following queries: Given the symptoms \emph {fever, nausea} and \emph {fatigue}, (a) Control: What is the probability that the patient has a respiratory disease (as opposed to the symptoms being caused by the presence of a gastrointestinal disease)?, (b) With dud alternatives: What is the probability that the patient has a respiratory disease (as opposed to the symptoms being caused by the presence of gastroenteritis, stomach cancer, or any other gastrointestinal disease)? The estimate from the control chain is higher than from the chain for which dud alternatives are presented. The difference between these estimates is represented by the red line and the effect diminishes as the number of samples increases\relax }}{36}{figure.caption.8}
\contentsline {figure}{\numberline {2.5}{\ignorespaces \textbf {Self-generation effect}. MCMC estimates for the following query: Given the symptoms \emph {fever} and \emph {fatigue}, (a) Self-generated: What are the two most likely respiratory diseases to have caused these symptoms? Estimate the probability that these symptoms are caused by either of these two diseases. (b) Other-generated: What is the probability that these symptoms were caused by the presence of a cold or respiratory flu (two most likely respiratory diseases to have caused these symptoms returned by the first chain)? The estimate from the other-generated chain is higher than from the self-generated chain. The difference between these estimates is represented by the red line and the effect decreases as the number of samples increases\relax }}{37}{figure.caption.9}
\contentsline {figure}{\numberline {2.6}{\ignorespaces \textbf {Anchoring and adjustment}. The y axis represents the difference in the probabilities of respiratory flu and stomach flu given the symptoms \textit {fever} and \textit {fatigue} as returned by two different chains that are initialized differently. The chains are initialized in the two different clusters, at hypotheses other than the focal hypotheses of \textit {respiratory} or \textit {stomach flu}. Before reaching convergence, the chain initialized in cluster 1 of respiratory diseases places higher probability on respiratory flu, than the chain initialized in cluster 2 of gastrointestinal diseases. The net difference between the two chains diminishes as the number of samples increases.\relax }}{39}{figure.caption.10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces \textbf {The crowd within}. Errors in the MCMC estimates for the following query: Given the symptoms \emph {nausea} and \emph {shortness of breath}, what is the probability that these were caused by the presence of a respiratory disease? The estimates are averaged either over samples from the same individual (blue) or over samples from different individuals (red)\relax }}{41}{figure.caption.11}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \textbf {Experimental setup}. Participants were asked to estimate the conditional probability using a slider bar within a 20-second time limit.\relax }}{48}{figure.caption.13}
\contentsline {figure}{\numberline {2.9}{\ignorespaces \textbf {Experiment 1 results}. Mean probability estimates for each condition. Error bars represent the 95\% confidence interval of the mean. Red dots show estimates from the MCMC model with 230 samples, assuming 6 hidden objects in the scene.\relax }}{49}{figure.caption.14}
\contentsline {figure}{\numberline {2.10}{\ignorespaces \textbf {Experiment 2 results}. Mean probability estimates for each condition. Error bars represent the 95\% confidence interval of the mean. Red dots show estimates from the MCMC model with 230 samples, assuming 6 hidden objects in the scene. Unpacking 1 is typical for cue object 1 and atypical for cue object 2; unpacking 2 is typical for cue object 2 and atypical for cue object 1.\relax }}{52}{figure.caption.16}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Demonstration of how MCMC sampling can give rise to sub- and super-additivity for different unpacked versions of the question : ``In the presence of a table, what is the probability that there is also another object starting with C?''. The color gradient indicates probability density. (a) The chain initialized with a typical unpacking starts at `chair', a high probability hypothesis, denoted by a darker shading, while the chain initialized with an atypical unpacking starts at `canoe', a low probability hypothesis, denoted by a lighter shading. (b) For the purposes of illustration we show the same new intermediate probability proposal of `toothbrush' being made to both chains. In the model, this proposal is randomly generated for each chain. (c) Since the probability of `toothbrush' is significantly higher than `canoe' the proposal is accepted by the atypically unpacked chain. But conversely since it is significantly less probable than `chair', is likely rejected by the typically unpacked chain. (d) The tendency for the typically unpacked chain to tarry in the high probability region of the queried object set, gives rise to sub-additivity, whereas the tendency for the atypically unpacked to get easily derailed into regions outside the queried object set gives rise to super-additivity.\relax }}{63}{figure.caption.19}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Different initializations}}}{63}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The same proposal made to both chains}}}{63}{subfigure.1.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Proposal gets accepted or rejected (Equation \ref {eq:MH-step})}}}{63}{subfigure.1.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Sub- and super-additivity}}}{63}{subfigure.1.4}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Theory schematic. (Left) Standard, memoryless framework in which a recognition model $Q_{"θ}(h|d)$ approximates the posterior over hypothesis $h$ given data $d$. The recognition model is parametrized by ${"θ}$ (e.g., a set of samples in the case of Monte Carlo methods). Memoryless inference builds a separate recognition model for each query. (Right) Amortized framework, in which the recognition model shares parameters across queries. After each new query, the recognition model updates the shared parameters. In this way, the model ``learns to infer.''\relax }}{66}{figure.caption.20}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Simulation of subadditivity and superadditivity effects under sample-based (top) and summary-based (bottom) amortization strategies. In all panels, the y-axis represents the unstandardized effect size for $\mathcal {Q}2$. Left panels show the effects of changing the sample size for $\mathcal {Q}1$; right panels show the effects of changing the sample size for $\mathcal {Q}2$. When sample size for one query is changed, sample size for the other query is held fixed at 230 \citep [the sample size estimated by][]{dasgupta17}.\relax }}{68}{figure.caption.21}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Experimental setup. Participants were asked to estimate the conditional probability using a slider bar within a 20-second time limit.\relax }}{72}{figure.caption.22}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Experiment 1: Differences between $\mathcal {Q}2$ responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.\relax }}{75}{figure.caption.24}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Trial-by-trial analyses of Experiment 1. Difference between $\mathcal {Q}1$ responses and true probability (as assessed by our MCMC model) plotted against the same quantity for $\mathcal {Q}2$. Lines show the least-squares fit with standard error bands.\relax }}{76}{figure.caption.25}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Experiment 2: Differences between $\mathcal {Q}2$ responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.\relax }}{80}{figure.caption.27}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Trial-by-trial analyses of Experiment 2. Relationship between difference between $\mathcal {Q}1$ responses and true probability (as assessed by our MCMC model) and $\mathcal {Q}2$ responses and true probability. Lines show the least-squares fit with standard error bands.\relax }}{82}{figure.caption.28}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Experiment 3: Differences between $\mathcal {Q}2$ responses for each condition and an average packed baseline. A negative relative mean estimate indicates a superadditivity effect and a positive relative mean estimate a subadditivity effect. Error bars represent the standard error of the mean.\relax }}{85}{figure.caption.30}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Trial-by-trial analyses of Experiment 3. Relationship between difference between $\mathcal {Q}1$ responses and true probability (as assessed by our MCMC model) and $\mathcal {Q}2$ responses and true probability. Lines show the least-squares fit with standard error bands.\relax }}{87}{figure.caption.31}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf {Schematics of different inference methods}. (A) Memoryless inference recomputes the variational parameters ${"φ}$ from scratch for each new set of observations, resulting in an approximate posterior $Q_{"φ}$ that is unique for each $d$. (B) Amortized inference allows some variational parameters to be shared across queries, optimizing them such that $Q_{"φ}$ is a good approximation \emph {in expectation} over the query distribution. (C) Schematic of how we implemented this framework with a neural network function approximator in the Learned Inference Model, with low capacity (1 hidden unit). (D) Schematic of a neural network function approximator in the Learned Inference Model, with high capacity (5 hidden units).\relax }}{108}{figure.caption.32}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Memoryless inference}}}{108}{subfigure.1.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Amortized inference}}}{108}{subfigure.1.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Learned Inference Model with 1 hidden unit}}}{108}{subfigure.1.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Learned Inference Model with 5 hidden units}}}{108}{subfigure.1.4}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf {Schematic demonstration of how the approximate posterior depends on the query distribution}. (A) The true posterior probability $P$ (indicated by colors on the heatmap), as a function of the prior and likelihood for a generative model in which $h \sim \text {Bernoulli}(p_0)$ and $d|h \sim \text {Bernoulli}(p_l)$. The contour lines depict the query distribution. (B) The approximate posterior $Q$ computed by the Learned Inference Model, averaged over the query distribution. The approximation is better for areas that are sufficiently covered by the query distribution. (C) The average KL divergence between the true and approximate posteriors. Higher divergence occurs in areas that are covered less by the query distribution. \relax }}{109}{figure.caption.33}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {True posterior P}}}{109}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Approximate posterior Q}}}{109}{subfigure.2.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {KL$ [Q||P ]$}}}{109}{subfigure.2.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \textbf {Simulation of inferential errors in binary symmetric problems with non-uniform priors}. $P(h | d)$ represents true posterior probabilities, $Q(h | d)$ represents subjective posterior probabilities. Plots show prior log-odds on the x axis, and the subjective prior log-odds calculated as the subjective posterior log-odds adjusted for subjective response to the likelihood (as modulated by $\mathaccentV {hat}05E{{"α}}_L$). (A) Data aggregated by \cite {benjamin18}. (B) Simulation with low-capacity (2 hidden nodes) Learned Inference Model. (C) Simulation with high-capacity (8 hidden nodes) Learned Inference Model. The shaded curves show the linear and nonlinear (LOESS) regression functions with 95\% confidence bands.\relax }}{115}{figure.caption.35}
\contentsline {figure}{\numberline {4.5}{\ignorespaces \textbf {Simulations of inferential errors with high capacity and a biased query distribution}. $P(h | d)$ represents true posterior probabilities, $Q(h | d)$ represents subjective posterior probabilities. (A) Simulation of high-capacity (8 hidden units) Learned Inference Model. (B) Simulation of low-capacity (2 hidden units) Learned Inference Model with biased query distribution. Left: subjective posterior log-odds vs. Bayesian posterior log-odds. Middle: estimated sensitivity to the likelihood $\mathaccentV {hat}05E{{"α}}_L$ vs. sample size $N$. Right: estimated sensitivity to the likelihood vs. diagnosticity ${"θ}$. The shaded curves show the linear and nonlinear (LOESS) regression functions with 95\% confidence bands.\relax }}{116}{figure.caption.36}
\contentsline {figure}{\numberline {4.6}{\ignorespaces \textbf {Strength and weight in probabilistic judgment}. (A) Regression coefficients reported in \cite {griffin1992weighing}. (B) Regression coefficients estimated from simulations of the Learned Inference Model. Error bars represent the standard error of the mean.\relax }}{119}{figure.caption.38}
\contentsline {figure}{\numberline {4.7}{\ignorespaces \textbf {Variance explained by strength and weight independently}. These plots show regressions between the log of the strength or weight of the evidence against the log of the posterior log-odds. (A) For samples drawn from the true generative process, the strength explains more variance in the posterior. (B) For the stimuli used in \cite {griffin1992weighing}, the weight explains almost none of the variance in the log posterior log-odds, whereas the strength explains a much higher amount of the variance. \relax }}{120}{figure.caption.39}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{120}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{120}{subfigure.7.2}
\contentsline {figure}{\numberline {4.8}{\ignorespaces \textbf {Screen shots of urn experiment}. (A) In the condition with informative priors and uninformative likelihoods, the wheel of fortune had urn probabilities of $0.7, 0.8$, or $0.9$. The proportions of blue balls in the urns was $0.5$ or $0.6$. (B) In the condition with uninformative priors and informative likelihoods, the wheel of fortune had urn probabilities of $0.5$ or $0.6$. The proportions of blue balls in the urns was $0.7, 0.8$, or $0.9$.\relax }}{122}{figure.caption.40}
\contentsline {figure}{\numberline {4.9}{\ignorespaces \textbf {Results of urn experiment}. The y-axis shows estimates for the regression coefficients ${"α}_L$ and ${"α}_P$ (see Equation \ref {eq:sysneg}), and the x-axis represents the experimental condition. (A) Subjects weighted the prior more in the informative prior than in the informative likelihood condition. (B) Subjects weighted the likelihood more in the informative likelihood than in the informative prior condition. (C) The Learned Inference Model weights the prior more in the informative prior condition as compared to in the informative likelihood condition. (D) The Learned Inference Model weights the likelihood more in the informative likelihood condition as compared in the informative prior condition. Error bars represent the standard errors of the regression coefficients.\relax }}{124}{figure.caption.41}
\contentsline {figure}{\numberline {4.10}{\ignorespaces \textbf {Base rate neglect within and between subjects}. The y-axis shows the reaction to the prior as measured in predictions from the Learned Inference Model, the x-axis shows the different conditions. Reaction to the prior here is measured by the difference between the responses given to test queries in which the base rate was $85\%$ and those in which the base rate was $15\%$. Thus, a greater difference indicates a stronger reaction to prior information. The model simulations of the within-subjects design show a stronger reaction to the base rates than the simulations of the between-subjects design (which shows no reaction to the base rate at all). Both of these conditions produce under-reaction to the base rate compared to the Bayes-optimal judgment.\relax }}{127}{figure.caption.42}
\contentsline {figure}{\numberline {4.11}{\ignorespaces \textbf {Inferential errors in a continuous domain}. (A) Reanalysis of data from the payoff prediction task collected by \cite {gershman2017blessing}. (B) Simulations of the Learned Inference Model. Each panel shows subjective updates from prior to posterior (${"Δ}$Data) on the y-axis and the update of a rational (hierarchical) model (${"Δ}$Rational) on the x-axis. Error bars represent the standard error of the mean. Gray lines represent $y=x$.\relax }}{130}{figure.caption.43}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Data from humans}}}{130}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Simulation results}}}{130}{subfigure.11.2}
\contentsline {figure}{\numberline {4.12}{\ignorespaces \textbf {Belief bias}. Top: experimental data. Bottom: simulations of the Learned Inference Model. (A) Empirical results for the believable condition \citep {cohen2017beliefs}. (B) Empirical results for the unbelievable condition. (C) Simulated results for the believable condition. (D) Simulated results for the unbelievable condition. The correlation between the actual and estimated posterior is closer to 1 (i.e., exact Bayesian inference) in the believable condition than in the unbelievable condition. The Learned Inference Model reproduces this effect. \relax }}{133}{figure.caption.44}
\contentsline {figure}{\numberline {4.13}{\ignorespaces \textbf {Memory effect}. (A) Observed subadditivity effect in query 2 reported in \cite {dasgupta2018remembrance}. Cues that were similar to a previous query showed a higher effect than cues that were less similar, indicating strategic reuse of past computation. (B) Simulated subadditivity effect. Provided that the model was trained to exhibit a subadditivity effect in a first query, this effect remained stronger for similar queries than for dissimilar queries. Error bars represent the standard error of the mean. \relax }}{136}{figure.caption.45}
\contentsline {figure}{\numberline {4.14}{\ignorespaces \textbf {Correction prior.} (A) Simulation results from the correction prior model in \cite {zhu_sanborn_chater_2018} exhibiting conservatism. Black line represents the optimal response and the colored lines show estimates from different parameterizations of the model. (B) Quadratic relation between the variance of subjective probability estimates and mean subjective probability estimates, as observed by \cite {zhu_sanborn_chater_2018}. Points show data points from previous empirical studies. The line shows best fit quadratic fit to this data. (C) The Learned Inference Model replicates the conservatism effect. Points represent mean estimates from our model, the pink line represents the best fit linear regression to these points, the black line represents the optimal response. (D) The Learned Inference Model replicates the variance effect. Points represent variance of the subjective responses from our model for different mean subjective responses. The pink line represents the best fit quadratic fit to these points.\relax }}{141}{figure.caption.46}
\contentsline {figure}{\numberline {4.15}{\ignorespaces \textbf {Performance of the L-HBM}. Simulation results of a hierarchical Bayesian model that infers the underlying parameters in the the experiment reported by \cite {gershman2017blessing}. The Y-axis shows the L-HBM's updates from prior to posterior (${"Δ}$Data) and the X-axis shows the update of a rational (hierarchical) model (${"Δ}$Rational; a HBM that knows the true parameters for the underlying generative process). Error bars represent the standard error of the mean. Gray line represents $y=x$.\relax }}{155}{figure.caption.47}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces InferSent architecture \citep {Conneau:2017uf}.\relax }}{164}{figure.caption.48}
\contentsline {figure}{\numberline {5.2}{\ignorespaces BOW embedding confusion matrices, with normalized rows.\relax }}{169}{figure.caption.52}
\contentsline {figure}{\numberline {5.3}{\ignorespaces InferSent embedding confusion matrices, with normalized rows.\relax }}{169}{figure.caption.53}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces a) Active vs Random Conditional, b)Associative Baseline vs Active Conditional, where intervened node has a parent\relax }}{200}{figure.caption.64}
\contentsline {figure}{\numberline {6.2}{\ignorespaces \textbf {Experiment 1. Agents do causal reasoning from observational data.} a) Average performance of the agents tested in this experiment. b) Performance split by the presence or absence of at least one parent (Parent and Orphan respectively) on the externally intervened node. c) Quiz phase for a test CBN. Green (red) edges indicate a weight of $+1$ ($-1$). Black represents the intervened node, green (red) nodes indicate a positive (negative) value, white indicates a zero value. The blue circles indicate the agent's choice. Left panel: The undirected version of ${\cal G}$ and the nodes taking the mean values prescribed by $p(X_{1:N\setminus j }|X_j=-5)$, including backward inference to the intervened node's parent. The Associative Baseline's choice is consistent with maximizing these (incorrect) node values. Right panel: ${\cal G}_{\rightarrow X_j=-5}$ and the nodes taking the mean values prescribed by $p_{\rightarrow X_j=-5}(X_{1:N\setminus j }|X_j=-5)$. The Active-Conditional Agent's choice is consistent with maximizing these (correct) node values.\relax }}{201}{figure.caption.65}
\contentsline {figure}{\numberline {6.3}{\ignorespaces \textbf {Experiment 2. Agents do causal reasoning from interventional data.} a) Average performance of the agents tested in this experiment. See main text for details. b) Performance split by the presence or absence of unobserved confounders (abbreviated as Conf. and Unconf.). c) Quiz phase for a test CBN. See Figure \ref {fig:expt1} for a legend. Here, the left panel shows the full $\cal G$ and the nodes taking the mean values prescribed by $p(X_{1:N\setminus j }|X_j=-5)$. We see that the Active-Cond Agent's choice is consistent with choosing based on these (incorrect) node values. The right panel shows ${\cal G}_{\rightarrow X_j=-5}$ and the nodes taking the mean values prescribed by $p_{\rightarrow X_j=-5}(X_{1:N\setminus j }|X_j=-5)$. We see that the Active-Int. Agent's choice is consistent with maximizing on these (correct) node value.\relax }}{203}{figure.caption.66}
\contentsline {figure}{\numberline {6.4}{\ignorespaces Active and Random Interventional Agents\relax }}{203}{figure.caption.67}
\contentsline {figure}{\numberline {6.5}{\ignorespaces (a): Directed acyclic graph. The node $X_3$ is a collider on the path $X_1 \rightarrow X_3 \leftarrow X_2$ and a non-collider on the path $X_2\rightarrow X_3\rightarrow X_4$. (b): Cyclic graph obtained from (a) by adding a link from $X_4$ to $X_1$.\relax }}{209}{figure.caption.68}
\contentsline {figure}{\numberline {6.6}{\ignorespaces (a): A CBN\nobreakspace {}${\cal G}$ with a confounder for the effect of exercise ($E$) on heath ($H$) given by age ($A$). (b): Intervened CBN\nobreakspace {}${\cal G}_{\rightarrow E=e}$.\relax }}{210}{figure.caption.69}
\contentsline {figure}{\numberline {6.7}{\ignorespaces Experiment 3. Agents do counterfactual reasoning. a) Performance of the agents tested in this experiment. Note that performance can be above 1.0 since the counterfactual agent can theoretically perform better than the optimal interventional baseline, which doesn't have access to noise information. See main text for details. b) Performance split by if the maximum node value in the quiz phase is degenerate (Deg.) or distinct (Dist.). c) Quiz phase for an example test-CBN. See Figures in Main text for a legend. Here, the left panel shows ${\cal G}_{\rightarrow X_j=-5}$ and the nodes taking the mean values prescribed by $p_{\rightarrow X_j=-5}(X_{1:N\setminus j }|X_j=-5)$. We see that the Active-Int. Agent's choice is consistent with maximizing on these node values, where it makes a random choice between two nodes with the same value. The right panel panel shows ${\cal G}_{\rightarrow X_j=-5}$ and the nodes taking the exact values prescribed by the means of $p_{\rightarrow X_j=-5}(X_{1:N\setminus j }|X_j=-5)$, combined with the specific randomness inferred from the previous time step. As a result of accounting for the randomness, the two previously degenerate maximum values are now distinct. We see that the Active-CF. agent's choice is consistent with maximizing on these node values.\relax }}{214}{figure.caption.70}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{214}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{214}{subfigure.5.2}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{214}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{214}{subfigure.6.2}
\contentsline {figure}{\numberline {6.8}{\ignorespaces Active and Random Counterfactual Agents\relax }}{215}{figure.caption.71}
\contentsline {figure}{\numberline {6.9}{\ignorespaces Results for non-linear graphs. (a) Comparing average episode reward for agents trained with different data. (b) Comparing information phase intervention policies. \relax }}{215}{figure.caption.72}
\contentsline {figure}{\numberline {6.10}{\ignorespaces Results for $N=6$ graphs. (a) Comparing average episode reward for agents trained with different data. (b) Comparing information phase intervention policies. \relax }}{216}{figure.caption.73}
