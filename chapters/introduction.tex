%!TEX root = ../dissertation.tex
\chapter{General Introduction}
\label{chap:intro}

The flexibility and efficiency of human intelligence far surpasses what is possible with current artificially intelligent systems. 

Significant progress towards understanding this flexibility has been made possible by structured, Bayesian models of cognition. Program induction etc, beyond stimulus-response.

However, a crucial shortcoming of these models is intractable learning and intractable inference. Despite significant advances in how they explain behavior in humans, these shortcomings have also torpedoed the adoption of such structured models in modern AI. While the ability of these models to replicate human behavior has been hugely insightful, they remain "as-if" models that do not provide a complete model of how humans actually work. This view has been fueled by much evidence that shows that people aren't quite doing this anyway, with biases and heuristics.

In this thesis, I provide a solution to these concerns via a renewed consideration of the environment in which intelligent systems act. 

Most previous approaches have focused primarily on the internal mechanisms of human behavior, based on lab tests that may not match participants' previous real-world experience. The analogous concern also exists with the study of AI, where progress is reported largely by new models and mechanisms reporting improved performance on unchanging, often arbitrarily selected, standardized data sets. A crucial insight is that humans are not a general purpose computing machine, and therefore neither should AI that hopes to emulate human intelligence. Humans have developed -- both over evolutionary and lifetime time scales -- to solve specific kinds of problems. Our environment strongly affects our learning and inference procedures. This is further highlighted by the fact that humans have limited computing resources, and therefore are in more dire need to adapt to their environments and selectively optimize performance where it matters. Learning about things that don't occur often is often not even possible due to limited experience, and is largely not worth it given the cost on computation. 
Herb Simon / Brunswick = importance f the environment.

The main contributions of my thesis therefore are to a) alleviate the intractability of structured inference, thereby providing a more complete picture of human inference that accounts for our limitations. This also suggests ways to incorporate these structured models into artificial agents, via these tractable, computationally inexpensive, approaches  b) reconcile empirical evidence that shows that humans can be both very optimal as well as very biased depending on various factors, and c) suggest entirely new ways to understand and engineer artificial systems, via manipulation of the environments in which they learn and function.

\paragraph{Outline}

In Chapter \ref{chap:psych}, I review the theoretical framework surrounding human probabilistic inference. I first review rational Bayesian accounts, followed by a review of boundedly rational approaches. Finally I discuss ecological rationality -- a specific subset of these boundedly rational approaches that explicitly posits adaptation to structure in the environment. I highlight how these approaches fall short, and outline how this thesis suggests a more complete picture. In Chapters \ref{chap:approx} and \ref{chap:amort} I review the conceptual background for this thesis. In Chapter \ref{chap:approx} I cover technical background on approximate probabilistic inference. In Chapter \ref{chap:amort} I introduce a formal notion of computational re-use i.e. amortization, and how it can lead to algorithmic solutions to ecological rational behavior.

%In this thesis, I show how adaptation to environments (as necessary under resource constraints) can both a) render inference more tractable on average, and b) explain deviations from normative Bayesian inference.

In Chapter \ref{chap:MCMC}, I study human inferences in large hypothesis spaces. This is a challenging problem, where exact inference is intractable. I demonstrate that a sample-based approximation to this posterior based on Markov chain Monte Carlo, under ecologically rational constraints, can replicate the specific kinds of biases observed in human inference in such large hypothesis spaces. 
% This model relies on two crucial components to replicate these deviations from normativity: first, a small number of samples, and second, initialization based on question framing. I argue that these components are ecologically rational: humans have limited cognitive resources, hindering the possibility of a large number of samples in the approximation, and initialization based on question framing is reasonable since the context of queries in the environment are often related to and informative of the optimal response. 
Further, in small hypothesis spaces, this model returns optimal responses. This allows us to parsimoniously explain both the rationality as well as the various kinds of irrationality of human inference observed in different situations, all within a framework that makes no unrealistic demands of computational power. In Chapter \ref{chap:MCMC_amort} I expand on the role of the environment in sampling frameworks. I discuss models for, and empirically demonstrate, re-use of computation in consecutive related queries. This kind of re-use -- or amortization -- is ecologically rational since queries in the real world are often related.

In Chapter \ref{chap:LTI}, I study I discuss amortization in much greater detail. In particular, I discuss amortization in a variational framework, and discuss how it is more amenable to flexible re-use. I demonstrate how this framework can replicate several cognitive biases that involve context-sensitive sub-optimal reactions to different sources of information -- including base-rate neglect, conservatism and belief bias -- as well as various various other effects such as the response variability in probabilistic judgments, effects of experimental design, and certain memory effects. This work posits an algorithmic approach, via amortization of inference, to understanding ecologically rational heuristic behavior. 

In Chapters \ref{chap:sentences} and \ref{chap:causal}, I study the role of the environment in modern artificial intelligence (AI). The study and development of AI has similarly largely neglected the crucial role of the environment in shaping the inference strategies learned by intelligent systems, choosing instead to focus only on the internal mechanisms. In Chapter \ref{chap:sentences}, I demonstrate how ecological rationality can explain several kinds of errors in modern language learning systems -- analogous to how they explained human biases in previous chapters. I outline an approach that leverages this insight to better asses and potentially also improve, these systems. In Chapter \ref{chap:causal}, I demonstrate how we can leverage the strong influence the environment has on the inference procedures learned, to engineer the inference procedures we want. I show that manipulation of the environment, with a very simple learning architecture, can give rise to complex behaviors including causal inference procedures and active information seeking behavior. The strong control we have over the environments encountered by artificial systems also allows new investigations into ecological rationality, that are impossible with humans.