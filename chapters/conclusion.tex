%!TEX root = ../dissertation.tex
\chapter{Conclusion}
\label{chap:conclusion}

The direct contributions of this thesis are threefold. First I develop a framework based on ecologically rational approximate inference that alleviates the intractability of inference in structured Bayesian models. This allows these powerful models to be taken more seriously, as more than as-if models and closer to mechanistic models of human cognition. Second, the process of approximation leads to specific kinds of deviations from normativity, that allow us to model various context-dependent deviations from normativity observed in human cognition. And finally, I suggest entirely new ways to understand and engineer artificial systems, via manipulation of the environments in which they learn and function. This also suggests links between the analysis of ecological rationality in humans and in machines, leading to new lines of research into how to understand both.

This thesis moves toward a solution to these concerns via by better considering the environment in which intelligent systems act. I will study how utilizing structure in the environment can bring plausibility to Bayesian models of human cognition by making inference in them more feasible. I show how this underlying structure can be learned and leveraged by considering the inference itself a learning problem, and using past inferences to improve future inferences via the re-use of computations (also called amortization of computations). This addresses several of the criticisms of computational-level theories that invoke structured Bayesian models by alleviating their computational costs, paving the path for these to be mechanistically grounded theories of human cognition. I demonstrate, with several new empirical results, that humans do indeed utilize environmental structure in their inferences via re-use of computation (Chapters \ref{chap:MCMC_amort} and \ref{chap:LTI}). 

The second crucial contribution of this thesis is that it can explain both how and why humans can sometimes be so close to optimal, and in other domains (with the same cognitive resources), so biased -- and biased in so many different context-sensitive ways. While previous approaches have attempted to bridge this gap, they fail to explain this domain sensitivity. By allowing for re-use of computations, we can account for both these aspects of domain sensitivity as follows. First, the extent of experience in a domain informs how easy and effective it is to re-use computations in that domain. More effective re-use in turn predicts better inferences with the same run-time resources. Therefore, if the amount of experience in different domains vary, we can get close to optimal inferences in a familiar domain, with poor inferences in unfamiliar ones. Second, the underlying structure discovered in different domains might be different. This can give to different context-sensitive inference procedures that make different kinds of errors and biases.

\section*{Open Questions and Future Work}