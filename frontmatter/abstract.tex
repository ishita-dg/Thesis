%!TEX root = ../dissertation.tex
% the abstract

%should state the problem, describe the methods and procedures used, and give the main results or conclusions of the research.

How do humans behave in intelligent ways in a complex and ever-changing world within limits on energy, data and time? How might an understanding of this help us build human-like artificial intelligence? Structured Bayesian models provide a normative account of rational behavior. Such models have made great progress towards understanding and describing the flexibility of human behavior, as well as the efficiency of their learning, in the presence of uncertainty and across a variety of domains. However, within limits on the resources normative Bayesian inferences are often intractable. In the kinds of high-dimensional spaces in which humans regularly function very adaptively, exact Bayesian inference would require tremendous computational resources that seems outside the realm of possibility given our brain's limited time and energy.
% Yet many human behaviors are very well replicated by exact Bayesian inference in complex, structured and high-dimensional models.
%Yet many behaviors in very high dimensional and structured domains have been characterized as close to Bayesian. How might humans perform these complex inferences efficiently? This leads to the second key criticism of normative inference. 
Further, extensive research in cognitive psychology and behavioral economics has demonstrated that human behavior is in fact `irrational', and often deviates significantly from normative Bayesian inference even in putatively simple problems, demonstrating a wide range of cognitive biases. Chapters \ref{chap:intro} and \ref{chap:psych} set the context for this thesis and discuss these problems and past solutions to them at greater length. 

The goal of this thesis is to build a more complete picture of human-like intelligence, that reconciles these seemingly contradicting views on human rationality. The key insight I build on is that humans are not general purpose computing machines, and neither should artificial systems that hope to emulate human intelligence. We are instead `ecologically rational', adapting to structures in our environments to make the best use of our limited access to data, time, and energy. 


%The goal of this thesis is move towards this more complete picture by taking a renewed consideration of the role of the environment in which intelligent systems learn and behave. 

The first main contribution of this thesis (in Chapters \ref{chap:approx} and \ref{chap:amort}) is to propose algorithms for approximating exact Bayesian inference within structured models, subject to limits on resources, that leverage underlying environmental structure to ease high computational costs. This adaptation to the environment is achieved by a process of amortization -- i.e. of seeing patterns in the sets of queries faced, and intelligently re-using computations performed in the service of previous queries. This makes inferences in structured Bayesian models, that were previously intractable, more plausible.

%An inference procedure that leverages environmental structure serves well for queries that are frequent, but can strongly bias inference in case of infrequent queries. 
Amortization can lend great speed ups when previous experience is similar to the query at hand. However, it can also lead to errors when the current query is not representative of past experience and this experience is erroneously re-used. Ecologically rational strategies work for the vast majority of frequent queries, but can lead to biases for infrequent queries. The second key contribution of this thesis (in Chapters \ref{chap:MCMC}--\ref{chap:LTI}) is to demonstrate that patterns of errors exactly replicate several human cognitive biases. I also test the new unique predictions of these models in several novel behavioral experiments.

Several machine-learning methods also implicitly amortize computations. I demonstrate that ecological rationality induced by this amortization can also explain behavioral patterns in modern machine learning. Further, in the case of machine intelligence, we have full control over the environments these systems have access too. A third contribution of this thesis (in Chapters \ref{chap:sentences} and \ref{chap:causal}) is to show how a better understanding of the role of the environment in the behaviors learned by ecologically rational systems can allow us to artificially engineer new kinds of intelligent behavior simply by engineering the environment.

These contributions reconcile the crucial shortcomings of a leading approach to human-like intelligence, by putting back in the spotlight the central role of the environment in shaping intelligent behavior. Ecological rationality has largely beein a philosophical construct so far. By taking an algorithmic approach to ecological rationality, I develop new, parsimonious theories of human probabilistic inference that can jointly explain its success and failures, as well as propose new ways to understand and build artificially intelligent systems.
